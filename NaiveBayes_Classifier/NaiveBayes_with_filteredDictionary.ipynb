{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f12e31-f9ad-4f97-8ddd-ff0f75fcfb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'000/000': 'ham',\n",
       " '000/001': 'spam',\n",
       " '000/002': 'spam',\n",
       " '000/003': 'ham',\n",
       " '000/004': 'spam',\n",
       " '000/005': 'ham',\n",
       " '000/006': 'ham',\n",
       " '000/007': 'spam',\n",
       " '000/008': 'spam',\n",
       " '000/009': 'spam',\n",
       " '000/010': 'ham',\n",
       " '000/011': 'spam',\n",
       " '000/012': 'spam',\n",
       " '000/013': 'spam',\n",
       " '000/014': 'spam',\n",
       " '000/015': 'spam',\n",
       " '000/016': 'spam',\n",
       " '000/017': 'spam',\n",
       " '000/018': 'spam',\n",
       " '000/019': 'spam',\n",
       " '000/020': 'ham',\n",
       " '000/021': 'ham',\n",
       " '000/022': 'spam',\n",
       " '000/023': 'spam',\n",
       " '000/024': 'ham',\n",
       " '000/025': 'ham',\n",
       " '000/026': 'ham',\n",
       " '000/027': 'ham',\n",
       " '000/028': 'spam',\n",
       " '000/029': 'spam',\n",
       " '000/030': 'spam',\n",
       " '000/031': 'spam',\n",
       " '000/032': 'ham',\n",
       " '000/033': 'spam',\n",
       " '000/034': 'ham',\n",
       " '000/035': 'ham',\n",
       " '000/036': 'spam',\n",
       " '000/037': 'spam',\n",
       " '000/038': 'ham',\n",
       " '000/039': 'ham',\n",
       " '000/040': 'spam',\n",
       " '000/041': 'spam',\n",
       " '000/042': 'spam',\n",
       " '000/043': 'spam',\n",
       " '000/044': 'ham',\n",
       " '000/045': 'ham',\n",
       " '000/046': 'ham',\n",
       " '000/047': 'ham',\n",
       " '000/048': 'spam',\n",
       " '000/049': 'ham',\n",
       " '000/050': 'spam',\n",
       " '000/051': 'spam',\n",
       " '000/052': 'spam',\n",
       " '000/053': 'spam',\n",
       " '000/054': 'spam',\n",
       " '000/055': 'spam',\n",
       " '000/056': 'spam',\n",
       " '000/057': 'spam',\n",
       " '000/058': 'spam',\n",
       " '000/059': 'spam',\n",
       " '000/060': 'spam',\n",
       " '000/061': 'ham',\n",
       " '000/062': 'spam',\n",
       " '000/063': 'spam',\n",
       " '000/064': 'spam',\n",
       " '000/065': 'spam',\n",
       " '000/066': 'spam',\n",
       " '000/067': 'spam',\n",
       " '000/068': 'spam',\n",
       " '000/069': 'ham',\n",
       " '000/070': 'ham',\n",
       " '000/071': 'spam',\n",
       " '000/072': 'ham',\n",
       " '000/073': 'ham',\n",
       " '000/074': 'ham',\n",
       " '000/075': 'ham',\n",
       " '000/076': 'ham',\n",
       " '000/077': 'ham',\n",
       " '000/078': 'ham',\n",
       " '000/079': 'ham',\n",
       " '000/080': 'spam',\n",
       " '000/081': 'ham',\n",
       " '000/082': 'ham',\n",
       " '000/083': 'ham',\n",
       " '000/084': 'spam',\n",
       " '000/085': 'spam',\n",
       " '000/086': 'spam',\n",
       " '000/087': 'spam',\n",
       " '000/088': 'spam',\n",
       " '000/089': 'spam',\n",
       " '000/090': 'spam',\n",
       " '000/091': 'spam',\n",
       " '000/092': 'spam',\n",
       " '000/093': 'spam',\n",
       " '000/094': 'spam',\n",
       " '000/095': 'spam',\n",
       " '000/096': 'ham',\n",
       " '000/097': 'spam',\n",
       " '000/098': 'ham',\n",
       " '000/099': 'spam',\n",
       " '000/100': 'ham',\n",
       " '000/101': 'spam',\n",
       " '000/102': 'spam',\n",
       " '000/103': 'spam',\n",
       " '000/104': 'spam',\n",
       " '000/105': 'spam',\n",
       " '000/106': 'ham',\n",
       " '000/107': 'ham',\n",
       " '000/108': 'ham',\n",
       " '000/109': 'ham',\n",
       " '000/110': 'ham',\n",
       " '000/111': 'ham',\n",
       " '000/112': 'spam',\n",
       " '000/113': 'ham',\n",
       " '000/114': 'spam',\n",
       " '000/115': 'spam',\n",
       " '000/116': 'spam',\n",
       " '000/117': 'spam',\n",
       " '000/118': 'spam',\n",
       " '000/119': 'ham',\n",
       " '000/120': 'ham',\n",
       " '000/121': 'spam',\n",
       " '000/122': 'ham',\n",
       " '000/123': 'spam',\n",
       " '000/124': 'spam',\n",
       " '000/125': 'ham',\n",
       " '000/126': 'ham',\n",
       " '000/127': 'ham',\n",
       " '000/128': 'ham',\n",
       " '000/129': 'ham',\n",
       " '000/130': 'spam',\n",
       " '000/131': 'spam',\n",
       " '000/132': 'ham',\n",
       " '000/133': 'ham',\n",
       " '000/134': 'ham',\n",
       " '000/135': 'ham',\n",
       " '000/136': 'spam',\n",
       " '000/137': 'spam',\n",
       " '000/138': 'ham',\n",
       " '000/139': 'ham',\n",
       " '000/140': 'spam',\n",
       " '000/141': 'spam',\n",
       " '000/142': 'spam',\n",
       " '000/143': 'spam',\n",
       " '000/144': 'spam',\n",
       " '000/145': 'ham',\n",
       " '000/146': 'ham',\n",
       " '000/147': 'spam',\n",
       " '000/148': 'spam',\n",
       " '000/149': 'spam',\n",
       " '000/150': 'spam',\n",
       " '000/151': 'spam',\n",
       " '000/152': 'spam',\n",
       " '000/153': 'spam',\n",
       " '000/154': 'ham',\n",
       " '000/155': 'spam',\n",
       " '000/156': 'spam',\n",
       " '000/157': 'spam',\n",
       " '000/158': 'spam',\n",
       " '000/159': 'spam',\n",
       " '000/160': 'spam',\n",
       " '000/161': 'ham',\n",
       " '000/162': 'ham',\n",
       " '000/163': 'ham',\n",
       " '000/164': 'ham',\n",
       " '000/165': 'spam',\n",
       " '000/166': 'spam',\n",
       " '000/167': 'spam',\n",
       " '000/168': 'spam',\n",
       " '000/169': 'ham',\n",
       " '000/170': 'ham',\n",
       " '000/171': 'spam',\n",
       " '000/172': 'ham',\n",
       " '000/173': 'spam',\n",
       " '000/174': 'spam',\n",
       " '000/175': 'spam',\n",
       " '000/176': 'spam',\n",
       " '000/177': 'spam',\n",
       " '000/178': 'ham',\n",
       " '000/179': 'spam',\n",
       " '000/180': 'spam',\n",
       " '000/181': 'ham',\n",
       " '000/182': 'spam',\n",
       " '000/183': 'spam',\n",
       " '000/184': 'ham',\n",
       " '000/185': 'spam',\n",
       " '000/186': 'spam',\n",
       " '000/187': 'spam',\n",
       " '000/188': 'spam',\n",
       " '000/189': 'spam',\n",
       " '000/190': 'spam',\n",
       " '000/191': 'spam',\n",
       " '000/192': 'spam',\n",
       " '000/193': 'spam',\n",
       " '000/194': 'spam',\n",
       " '000/195': 'ham',\n",
       " '000/196': 'spam',\n",
       " '000/197': 'ham',\n",
       " '000/198': 'spam',\n",
       " '000/199': 'spam',\n",
       " '000/200': 'ham',\n",
       " '000/201': 'ham',\n",
       " '000/202': 'ham',\n",
       " '000/203': 'ham',\n",
       " '000/204': 'ham',\n",
       " '000/205': 'ham',\n",
       " '000/206': 'ham',\n",
       " '000/207': 'ham',\n",
       " '000/208': 'ham',\n",
       " '000/209': 'ham',\n",
       " '000/210': 'ham',\n",
       " '000/211': 'spam',\n",
       " '000/212': 'ham',\n",
       " '000/213': 'spam',\n",
       " '000/214': 'spam',\n",
       " '000/215': 'spam',\n",
       " '000/216': 'spam',\n",
       " '000/217': 'spam',\n",
       " '000/218': 'spam',\n",
       " '000/219': 'spam',\n",
       " '000/220': 'spam',\n",
       " '000/221': 'spam',\n",
       " '000/222': 'spam',\n",
       " '000/223': 'spam',\n",
       " '000/224': 'spam',\n",
       " '000/225': 'spam',\n",
       " '000/226': 'spam',\n",
       " '000/227': 'spam',\n",
       " '000/228': 'spam',\n",
       " '000/229': 'spam',\n",
       " '000/230': 'spam',\n",
       " '000/231': 'spam',\n",
       " '000/232': 'spam',\n",
       " '000/233': 'spam',\n",
       " '000/234': 'spam',\n",
       " '000/235': 'spam',\n",
       " '000/236': 'spam',\n",
       " '000/237': 'spam',\n",
       " '000/238': 'ham',\n",
       " '000/239': 'ham',\n",
       " '000/240': 'ham',\n",
       " '000/241': 'ham',\n",
       " '000/242': 'ham',\n",
       " '000/243': 'ham',\n",
       " '000/244': 'spam',\n",
       " '000/245': 'ham',\n",
       " '000/246': 'ham',\n",
       " '000/247': 'ham',\n",
       " '000/248': 'ham',\n",
       " '000/249': 'spam',\n",
       " '000/250': 'ham',\n",
       " '000/251': 'ham',\n",
       " '000/252': 'ham',\n",
       " '000/253': 'ham',\n",
       " '000/254': 'spam',\n",
       " '000/255': 'ham',\n",
       " '000/256': 'ham',\n",
       " '000/257': 'ham',\n",
       " '000/258': 'spam',\n",
       " '000/259': 'spam',\n",
       " '000/260': 'spam',\n",
       " '000/261': 'spam',\n",
       " '000/262': 'ham',\n",
       " '000/263': 'ham',\n",
       " '000/264': 'spam',\n",
       " '000/265': 'ham',\n",
       " '000/266': 'ham',\n",
       " '000/267': 'ham',\n",
       " '000/268': 'spam',\n",
       " '000/269': 'spam',\n",
       " '000/270': 'spam',\n",
       " '000/271': 'spam',\n",
       " '000/272': 'spam',\n",
       " '000/273': 'spam',\n",
       " '000/274': 'spam',\n",
       " '000/275': 'spam',\n",
       " '000/276': 'spam',\n",
       " '000/277': 'spam',\n",
       " '000/278': 'spam',\n",
       " '000/279': 'spam',\n",
       " '000/280': 'spam',\n",
       " '000/281': 'spam',\n",
       " '000/282': 'spam',\n",
       " '000/283': 'spam',\n",
       " '000/284': 'spam',\n",
       " '000/285': 'spam',\n",
       " '000/286': 'spam',\n",
       " '000/287': 'spam',\n",
       " '000/288': 'spam',\n",
       " '000/289': 'spam',\n",
       " '000/290': 'spam',\n",
       " '000/291': 'ham',\n",
       " '000/292': 'spam',\n",
       " '000/293': 'spam',\n",
       " '000/294': 'ham',\n",
       " '000/295': 'spam',\n",
       " '000/296': 'spam',\n",
       " '000/297': 'spam',\n",
       " '000/298': 'ham',\n",
       " '000/299': 'spam',\n",
       " '001/000': 'spam',\n",
       " '001/001': 'ham',\n",
       " '001/002': 'ham',\n",
       " '001/003': 'spam',\n",
       " '001/004': 'spam',\n",
       " '001/005': 'spam',\n",
       " '001/006': 'ham',\n",
       " '001/007': 'ham',\n",
       " '001/008': 'spam',\n",
       " '001/009': 'spam',\n",
       " '001/010': 'spam',\n",
       " '001/011': 'spam',\n",
       " '001/012': 'spam',\n",
       " '001/013': 'spam',\n",
       " '001/014': 'spam',\n",
       " '001/015': 'spam',\n",
       " '001/016': 'spam',\n",
       " '001/017': 'spam',\n",
       " '001/018': 'spam',\n",
       " '001/019': 'spam',\n",
       " '001/020': 'ham',\n",
       " '001/021': 'ham',\n",
       " '001/022': 'spam',\n",
       " '001/023': 'spam',\n",
       " '001/024': 'spam',\n",
       " '001/025': 'spam',\n",
       " '001/026': 'spam',\n",
       " '001/027': 'spam',\n",
       " '001/028': 'ham',\n",
       " '001/029': 'spam',\n",
       " '001/030': 'ham',\n",
       " '001/031': 'ham',\n",
       " '001/032': 'ham',\n",
       " '001/033': 'ham',\n",
       " '001/034': 'ham',\n",
       " '001/035': 'ham',\n",
       " '001/036': 'ham',\n",
       " '001/037': 'spam',\n",
       " '001/038': 'spam',\n",
       " '001/039': 'ham',\n",
       " '001/040': 'spam',\n",
       " '001/041': 'spam',\n",
       " '001/042': 'spam',\n",
       " '001/043': 'ham',\n",
       " '001/044': 'ham',\n",
       " '001/045': 'ham',\n",
       " '001/046': 'ham',\n",
       " '001/047': 'ham',\n",
       " '001/048': 'ham',\n",
       " '001/049': 'ham',\n",
       " '001/050': 'spam',\n",
       " '001/051': 'spam',\n",
       " '001/052': 'spam',\n",
       " '001/053': 'spam',\n",
       " '001/054': 'spam',\n",
       " '001/055': 'spam',\n",
       " '001/056': 'spam',\n",
       " '001/057': 'spam',\n",
       " '001/058': 'spam',\n",
       " '001/059': 'spam',\n",
       " '001/060': 'spam',\n",
       " '001/061': 'spam',\n",
       " '001/062': 'spam',\n",
       " '001/063': 'spam',\n",
       " '001/064': 'spam',\n",
       " '001/065': 'spam',\n",
       " '001/066': 'spam',\n",
       " '001/067': 'spam',\n",
       " '001/068': 'spam',\n",
       " '001/069': 'spam',\n",
       " '001/070': 'spam',\n",
       " '001/071': 'spam',\n",
       " '001/072': 'spam',\n",
       " '001/073': 'spam',\n",
       " '001/074': 'ham',\n",
       " '001/075': 'spam',\n",
       " '001/076': 'spam',\n",
       " '001/077': 'spam',\n",
       " '001/078': 'spam',\n",
       " '001/079': 'spam',\n",
       " '001/080': 'ham',\n",
       " '001/081': 'ham',\n",
       " '001/082': 'ham',\n",
       " '001/083': 'ham',\n",
       " '001/084': 'spam',\n",
       " '001/085': 'spam',\n",
       " '001/086': 'spam',\n",
       " '001/087': 'spam',\n",
       " '001/088': 'ham',\n",
       " '001/089': 'ham',\n",
       " '001/090': 'ham',\n",
       " '001/091': 'spam',\n",
       " '001/092': 'spam',\n",
       " '001/093': 'spam',\n",
       " '001/094': 'spam',\n",
       " '001/095': 'spam',\n",
       " '001/096': 'spam',\n",
       " '001/097': 'spam',\n",
       " '001/098': 'ham',\n",
       " '001/099': 'ham',\n",
       " '001/100': 'ham',\n",
       " '001/101': 'spam',\n",
       " '001/102': 'spam',\n",
       " '001/103': 'spam',\n",
       " '001/104': 'ham',\n",
       " '001/105': 'spam',\n",
       " '001/106': 'spam',\n",
       " '001/107': 'spam',\n",
       " '001/108': 'spam',\n",
       " '001/109': 'spam',\n",
       " '001/110': 'spam',\n",
       " '001/111': 'ham',\n",
       " '001/112': 'spam',\n",
       " '001/113': 'spam',\n",
       " '001/114': 'ham',\n",
       " '001/115': 'ham',\n",
       " '001/116': 'ham',\n",
       " '001/117': 'ham',\n",
       " '001/118': 'spam',\n",
       " '001/119': 'ham',\n",
       " '001/120': 'ham',\n",
       " '001/121': 'spam',\n",
       " '001/122': 'spam',\n",
       " '001/123': 'ham',\n",
       " '001/124': 'ham',\n",
       " '001/125': 'ham',\n",
       " '001/126': 'ham',\n",
       " '001/127': 'ham',\n",
       " '001/128': 'ham',\n",
       " '001/129': 'ham',\n",
       " '001/130': 'ham',\n",
       " '001/131': 'ham',\n",
       " '001/132': 'spam',\n",
       " '001/133': 'spam',\n",
       " '001/134': 'ham',\n",
       " '001/135': 'ham',\n",
       " '001/136': 'ham',\n",
       " '001/137': 'spam',\n",
       " '001/138': 'ham',\n",
       " '001/139': 'ham',\n",
       " '001/140': 'spam',\n",
       " '001/141': 'spam',\n",
       " '001/142': 'spam',\n",
       " '001/143': 'spam',\n",
       " '001/144': 'spam',\n",
       " '001/145': 'ham',\n",
       " '001/146': 'ham',\n",
       " '001/147': 'ham',\n",
       " '001/148': 'ham',\n",
       " '001/149': 'ham',\n",
       " '001/150': 'ham',\n",
       " '001/151': 'spam',\n",
       " '001/152': 'ham',\n",
       " '001/153': 'spam',\n",
       " '001/154': 'spam',\n",
       " '001/155': 'spam',\n",
       " '001/156': 'spam',\n",
       " '001/157': 'spam',\n",
       " '001/158': 'spam',\n",
       " '001/159': 'spam',\n",
       " '001/160': 'spam',\n",
       " '001/161': 'spam',\n",
       " '001/162': 'spam',\n",
       " '001/163': 'spam',\n",
       " '001/164': 'spam',\n",
       " '001/165': 'spam',\n",
       " '001/166': 'spam',\n",
       " '001/167': 'spam',\n",
       " '001/168': 'spam',\n",
       " '001/169': 'spam',\n",
       " '001/170': 'spam',\n",
       " '001/171': 'spam',\n",
       " '001/172': 'spam',\n",
       " '001/173': 'spam',\n",
       " '001/174': 'ham',\n",
       " '001/175': 'ham',\n",
       " '001/176': 'spam',\n",
       " '001/177': 'spam',\n",
       " '001/178': 'spam',\n",
       " '001/179': 'spam',\n",
       " '001/180': 'spam',\n",
       " '001/181': 'spam',\n",
       " '001/182': 'spam',\n",
       " '001/183': 'spam',\n",
       " '001/184': 'spam',\n",
       " '001/185': 'spam',\n",
       " '001/186': 'ham',\n",
       " '001/187': 'ham',\n",
       " '001/188': 'ham',\n",
       " '001/189': 'ham',\n",
       " '001/190': 'spam',\n",
       " '001/191': 'spam',\n",
       " '001/192': 'spam',\n",
       " '001/193': 'ham',\n",
       " '001/194': 'spam',\n",
       " '001/195': 'spam',\n",
       " '001/196': 'spam',\n",
       " '001/197': 'spam',\n",
       " '001/198': 'spam',\n",
       " '001/199': 'spam',\n",
       " '001/200': 'spam',\n",
       " '001/201': 'spam',\n",
       " '001/202': 'spam',\n",
       " '001/203': 'ham',\n",
       " '001/204': 'ham',\n",
       " '001/205': 'spam',\n",
       " '001/206': 'ham',\n",
       " '001/207': 'spam',\n",
       " '001/208': 'spam',\n",
       " '001/209': 'spam',\n",
       " '001/210': 'spam',\n",
       " '001/211': 'spam',\n",
       " '001/212': 'spam',\n",
       " '001/213': 'spam',\n",
       " '001/214': 'spam',\n",
       " '001/215': 'spam',\n",
       " '001/216': 'spam',\n",
       " '001/217': 'spam',\n",
       " '001/218': 'ham',\n",
       " '001/219': 'spam',\n",
       " '001/220': 'spam',\n",
       " '001/221': 'spam',\n",
       " '001/222': 'ham',\n",
       " '001/223': 'ham',\n",
       " '001/224': 'spam',\n",
       " '001/225': 'spam',\n",
       " '001/226': 'spam',\n",
       " '001/227': 'ham',\n",
       " '001/228': 'spam',\n",
       " '001/229': 'ham',\n",
       " '001/230': 'spam',\n",
       " '001/231': 'ham',\n",
       " '001/232': 'ham',\n",
       " '001/233': 'ham',\n",
       " '001/234': 'ham',\n",
       " '001/235': 'spam',\n",
       " '001/236': 'ham',\n",
       " '001/237': 'ham',\n",
       " '001/238': 'ham',\n",
       " '001/239': 'ham',\n",
       " '001/240': 'ham',\n",
       " '001/241': 'spam',\n",
       " '001/242': 'spam',\n",
       " '001/243': 'ham',\n",
       " '001/244': 'spam',\n",
       " '001/245': 'ham',\n",
       " '001/246': 'spam',\n",
       " '001/247': 'spam',\n",
       " '001/248': 'spam',\n",
       " '001/249': 'spam',\n",
       " '001/250': 'spam',\n",
       " '001/251': 'spam',\n",
       " '001/252': 'spam',\n",
       " '001/253': 'spam',\n",
       " '001/254': 'spam',\n",
       " '001/255': 'spam',\n",
       " '001/256': 'spam',\n",
       " '001/257': 'spam',\n",
       " '001/258': 'spam',\n",
       " '001/259': 'ham',\n",
       " '001/260': 'spam',\n",
       " '001/261': 'spam',\n",
       " '001/262': 'spam',\n",
       " '001/263': 'spam',\n",
       " '001/264': 'spam',\n",
       " '001/265': 'ham',\n",
       " '001/266': 'spam',\n",
       " '001/267': 'spam',\n",
       " '001/268': 'spam',\n",
       " '001/269': 'spam',\n",
       " '001/270': 'spam',\n",
       " '001/271': 'spam',\n",
       " '001/272': 'ham',\n",
       " '001/273': 'spam',\n",
       " '001/274': 'ham',\n",
       " '001/275': 'ham',\n",
       " '001/276': 'ham',\n",
       " '001/277': 'ham',\n",
       " '001/278': 'ham',\n",
       " '001/279': 'ham',\n",
       " '001/280': 'spam',\n",
       " '001/281': 'spam',\n",
       " '001/282': 'spam',\n",
       " '001/283': 'spam',\n",
       " '001/284': 'spam',\n",
       " '001/285': 'ham',\n",
       " '001/286': 'spam',\n",
       " '001/287': 'spam',\n",
       " '001/288': 'spam',\n",
       " '001/289': 'spam',\n",
       " '001/290': 'ham',\n",
       " '001/291': 'spam',\n",
       " '001/292': 'spam',\n",
       " '001/293': 'spam',\n",
       " '001/294': 'spam',\n",
       " '001/295': 'spam',\n",
       " '001/296': 'spam',\n",
       " '001/297': 'ham',\n",
       " '001/298': 'ham',\n",
       " '001/299': 'ham',\n",
       " '002/000': 'spam',\n",
       " '002/001': 'spam',\n",
       " '002/002': 'spam',\n",
       " '002/003': 'spam',\n",
       " '002/004': 'spam',\n",
       " '002/005': 'ham',\n",
       " '002/006': 'spam',\n",
       " '002/007': 'ham',\n",
       " '002/008': 'spam',\n",
       " '002/009': 'ham',\n",
       " '002/010': 'spam',\n",
       " '002/011': 'spam',\n",
       " '002/012': 'spam',\n",
       " '002/013': 'ham',\n",
       " '002/014': 'spam',\n",
       " '002/015': 'ham',\n",
       " '002/016': 'ham',\n",
       " '002/017': 'spam',\n",
       " '002/018': 'ham',\n",
       " '002/019': 'spam',\n",
       " '002/020': 'spam',\n",
       " '002/021': 'ham',\n",
       " '002/022': 'spam',\n",
       " '002/023': 'spam',\n",
       " '002/024': 'spam',\n",
       " '002/025': 'spam',\n",
       " '002/026': 'spam',\n",
       " '002/027': 'spam',\n",
       " '002/028': 'ham',\n",
       " '002/029': 'spam',\n",
       " '002/030': 'spam',\n",
       " '002/031': 'spam',\n",
       " '002/032': 'ham',\n",
       " '002/033': 'ham',\n",
       " '002/034': 'ham',\n",
       " '002/035': 'ham',\n",
       " '002/036': 'spam',\n",
       " '002/037': 'ham',\n",
       " '002/038': 'spam',\n",
       " '002/039': 'spam',\n",
       " '002/040': 'spam',\n",
       " '002/041': 'spam',\n",
       " '002/042': 'ham',\n",
       " '002/043': 'spam',\n",
       " '002/044': 'spam',\n",
       " '002/045': 'spam',\n",
       " '002/046': 'spam',\n",
       " '002/047': 'ham',\n",
       " '002/048': 'spam',\n",
       " '002/049': 'spam',\n",
       " '002/050': 'spam',\n",
       " '002/051': 'ham',\n",
       " '002/052': 'ham',\n",
       " '002/053': 'spam',\n",
       " '002/054': 'spam',\n",
       " '002/055': 'spam',\n",
       " '002/056': 'ham',\n",
       " '002/057': 'spam',\n",
       " '002/058': 'ham',\n",
       " '002/059': 'ham',\n",
       " '002/060': 'spam',\n",
       " '002/061': 'spam',\n",
       " '002/062': 'spam',\n",
       " '002/063': 'spam',\n",
       " '002/064': 'spam',\n",
       " '002/065': 'ham',\n",
       " '002/066': 'spam',\n",
       " '002/067': 'ham',\n",
       " '002/068': 'spam',\n",
       " '002/069': 'spam',\n",
       " '002/070': 'spam',\n",
       " '002/071': 'ham',\n",
       " '002/072': 'spam',\n",
       " '002/073': 'ham',\n",
       " '002/074': 'ham',\n",
       " '002/075': 'ham',\n",
       " '002/076': 'ham',\n",
       " '002/077': 'ham',\n",
       " '002/078': 'spam',\n",
       " '002/079': 'ham',\n",
       " '002/080': 'spam',\n",
       " '002/081': 'spam',\n",
       " '002/082': 'spam',\n",
       " '002/083': 'ham',\n",
       " '002/084': 'ham',\n",
       " '002/085': 'spam',\n",
       " '002/086': 'spam',\n",
       " '002/087': 'ham',\n",
       " '002/088': 'spam',\n",
       " '002/089': 'ham',\n",
       " '002/090': 'ham',\n",
       " '002/091': 'ham',\n",
       " '002/092': 'ham',\n",
       " '002/093': 'ham',\n",
       " '002/094': 'ham',\n",
       " '002/095': 'spam',\n",
       " '002/096': 'ham',\n",
       " '002/097': 'ham',\n",
       " '002/098': 'ham',\n",
       " '002/099': 'spam',\n",
       " '002/100': 'spam',\n",
       " '002/101': 'ham',\n",
       " '002/102': 'spam',\n",
       " '002/103': 'ham',\n",
       " '002/104': 'ham',\n",
       " '002/105': 'ham',\n",
       " '002/106': 'ham',\n",
       " '002/107': 'ham',\n",
       " '002/108': 'spam',\n",
       " '002/109': 'ham',\n",
       " '002/110': 'spam',\n",
       " '002/111': 'ham',\n",
       " '002/112': 'ham',\n",
       " '002/113': 'ham',\n",
       " '002/114': 'ham',\n",
       " '002/115': 'spam',\n",
       " '002/116': 'ham',\n",
       " '002/117': 'spam',\n",
       " '002/118': 'ham',\n",
       " '002/119': 'spam',\n",
       " '002/120': 'ham',\n",
       " '002/121': 'ham',\n",
       " '002/122': 'ham',\n",
       " '002/123': 'ham',\n",
       " '002/124': 'ham',\n",
       " '002/125': 'ham',\n",
       " '002/126': 'ham',\n",
       " '002/127': 'ham',\n",
       " '002/128': 'spam',\n",
       " '002/129': 'ham',\n",
       " '002/130': 'spam',\n",
       " '002/131': 'ham',\n",
       " '002/132': 'ham',\n",
       " '002/133': 'ham',\n",
       " '002/134': 'ham',\n",
       " '002/135': 'ham',\n",
       " '002/136': 'ham',\n",
       " '002/137': 'ham',\n",
       " '002/138': 'ham',\n",
       " '002/139': 'spam',\n",
       " '002/140': 'ham',\n",
       " '002/141': 'ham',\n",
       " '002/142': 'spam',\n",
       " '002/143': 'ham',\n",
       " '002/144': 'ham',\n",
       " '002/145': 'ham',\n",
       " '002/146': 'spam',\n",
       " '002/147': 'ham',\n",
       " '002/148': 'spam',\n",
       " '002/149': 'ham',\n",
       " '002/150': 'spam',\n",
       " '002/151': 'ham',\n",
       " '002/152': 'ham',\n",
       " '002/153': 'ham',\n",
       " '002/154': 'ham',\n",
       " '002/155': 'ham',\n",
       " '002/156': 'ham',\n",
       " '002/157': 'ham',\n",
       " '002/158': 'ham',\n",
       " '002/159': 'spam',\n",
       " '002/160': 'ham',\n",
       " '002/161': 'ham',\n",
       " '002/162': 'ham',\n",
       " '002/163': 'ham',\n",
       " '002/164': 'spam',\n",
       " '002/165': 'ham',\n",
       " '002/166': 'spam',\n",
       " '002/167': 'ham',\n",
       " '002/168': 'ham',\n",
       " '002/169': 'ham',\n",
       " '002/170': 'ham',\n",
       " '002/171': 'ham',\n",
       " '002/172': 'spam',\n",
       " '002/173': 'spam',\n",
       " '002/174': 'spam',\n",
       " '002/175': 'ham',\n",
       " '002/176': 'ham',\n",
       " '002/177': 'spam',\n",
       " '002/178': 'ham',\n",
       " '002/179': 'ham',\n",
       " '002/180': 'ham',\n",
       " '002/181': 'ham',\n",
       " '002/182': 'ham',\n",
       " '002/183': 'ham',\n",
       " '002/184': 'ham',\n",
       " '002/185': 'ham',\n",
       " '002/186': 'spam',\n",
       " '002/187': 'ham',\n",
       " '002/188': 'spam',\n",
       " '002/189': 'ham',\n",
       " '002/190': 'ham',\n",
       " '002/191': 'ham',\n",
       " '002/192': 'ham',\n",
       " '002/193': 'ham',\n",
       " '002/194': 'ham',\n",
       " '002/195': 'ham',\n",
       " '002/196': 'ham',\n",
       " '002/197': 'ham',\n",
       " '002/198': 'ham',\n",
       " '002/199': 'ham',\n",
       " '002/200': 'spam',\n",
       " '002/201': 'ham',\n",
       " '002/202': 'ham',\n",
       " '002/203': 'spam',\n",
       " '002/204': 'spam',\n",
       " '002/205': 'ham',\n",
       " '002/206': 'ham',\n",
       " '002/207': 'spam',\n",
       " '002/208': 'ham',\n",
       " '002/209': 'ham',\n",
       " '002/210': 'ham',\n",
       " '002/211': 'ham',\n",
       " '002/212': 'ham',\n",
       " '002/213': 'ham',\n",
       " '002/214': 'ham',\n",
       " '002/215': 'ham',\n",
       " '002/216': 'ham',\n",
       " '002/217': 'ham',\n",
       " '002/218': 'ham',\n",
       " '002/219': 'ham',\n",
       " '002/220': 'ham',\n",
       " '002/221': 'ham',\n",
       " '002/222': 'ham',\n",
       " '002/223': 'ham',\n",
       " '002/224': 'ham',\n",
       " '002/225': 'ham',\n",
       " '002/226': 'ham',\n",
       " '002/227': 'ham',\n",
       " '002/228': 'ham',\n",
       " '002/229': 'ham',\n",
       " '002/230': 'ham',\n",
       " '002/231': 'spam',\n",
       " '002/232': 'ham',\n",
       " '002/233': 'ham',\n",
       " '002/234': 'spam',\n",
       " '002/235': 'ham',\n",
       " '002/236': 'ham',\n",
       " '002/237': 'ham',\n",
       " '002/238': 'spam',\n",
       " '002/239': 'spam',\n",
       " '002/240': 'spam',\n",
       " '002/241': 'spam',\n",
       " '002/242': 'spam',\n",
       " '002/243': 'spam',\n",
       " '002/244': 'spam',\n",
       " '002/245': 'ham',\n",
       " '002/246': 'ham',\n",
       " '002/247': 'spam',\n",
       " '002/248': 'spam',\n",
       " '002/249': 'ham',\n",
       " '002/250': 'spam',\n",
       " '002/251': 'ham',\n",
       " '002/252': 'ham',\n",
       " '002/253': 'spam',\n",
       " '002/254': 'spam',\n",
       " '002/255': 'spam',\n",
       " '002/256': 'ham',\n",
       " '002/257': 'spam',\n",
       " '002/258': 'spam',\n",
       " '002/259': 'ham',\n",
       " '002/260': 'spam',\n",
       " '002/261': 'ham',\n",
       " '002/262': 'spam',\n",
       " '002/263': 'spam',\n",
       " '002/264': 'spam',\n",
       " '002/265': 'ham',\n",
       " '002/266': 'ham',\n",
       " '002/267': 'spam',\n",
       " '002/268': 'spam',\n",
       " '002/269': 'spam',\n",
       " '002/270': 'ham',\n",
       " '002/271': 'ham',\n",
       " '002/272': 'ham',\n",
       " '002/273': 'spam',\n",
       " '002/274': 'ham',\n",
       " '002/275': 'ham',\n",
       " '002/276': 'ham',\n",
       " '002/277': 'ham',\n",
       " '002/278': 'spam',\n",
       " '002/279': 'ham',\n",
       " '002/280': 'ham',\n",
       " '002/281': 'spam',\n",
       " '002/282': 'ham',\n",
       " '002/283': 'spam',\n",
       " '002/284': 'ham',\n",
       " '002/285': 'ham',\n",
       " '002/286': 'spam',\n",
       " '002/287': 'spam',\n",
       " '002/288': 'ham',\n",
       " '002/289': 'ham',\n",
       " '002/290': 'ham',\n",
       " '002/291': 'ham',\n",
       " '002/292': 'ham',\n",
       " '002/293': 'ham',\n",
       " '002/294': 'spam',\n",
       " '002/295': 'ham',\n",
       " '002/296': 'ham',\n",
       " '002/297': 'ham',\n",
       " '002/298': 'spam',\n",
       " '002/299': 'ham',\n",
       " '003/000': 'ham',\n",
       " '003/001': 'spam',\n",
       " '003/002': 'ham',\n",
       " '003/003': 'ham',\n",
       " '003/004': 'ham',\n",
       " '003/005': 'spam',\n",
       " '003/006': 'ham',\n",
       " '003/007': 'ham',\n",
       " '003/008': 'ham',\n",
       " '003/009': 'ham',\n",
       " '003/010': 'ham',\n",
       " '003/011': 'ham',\n",
       " '003/012': 'ham',\n",
       " '003/013': 'ham',\n",
       " '003/014': 'ham',\n",
       " '003/015': 'ham',\n",
       " '003/016': 'ham',\n",
       " '003/017': 'ham',\n",
       " '003/018': 'spam',\n",
       " '003/019': 'spam',\n",
       " '003/020': 'ham',\n",
       " '003/021': 'ham',\n",
       " '003/022': 'ham',\n",
       " '003/023': 'ham',\n",
       " '003/024': 'ham',\n",
       " '003/025': 'ham',\n",
       " '003/026': 'ham',\n",
       " '003/027': 'ham',\n",
       " '003/028': 'ham',\n",
       " '003/029': 'spam',\n",
       " '003/030': 'spam',\n",
       " '003/031': 'spam',\n",
       " '003/032': 'spam',\n",
       " '003/033': 'ham',\n",
       " '003/034': 'ham',\n",
       " '003/035': 'ham',\n",
       " '003/036': 'ham',\n",
       " '003/037': 'spam',\n",
       " '003/038': 'spam',\n",
       " '003/039': 'ham',\n",
       " '003/040': 'spam',\n",
       " '003/041': 'spam',\n",
       " '003/042': 'ham',\n",
       " '003/043': 'spam',\n",
       " '003/044': 'spam',\n",
       " '003/045': 'spam',\n",
       " '003/046': 'spam',\n",
       " '003/047': 'ham',\n",
       " '003/048': 'ham',\n",
       " '003/049': 'ham',\n",
       " '003/050': 'spam',\n",
       " '003/051': 'ham',\n",
       " '003/052': 'spam',\n",
       " '003/053': 'ham',\n",
       " '003/054': 'spam',\n",
       " '003/055': 'spam',\n",
       " '003/056': 'spam',\n",
       " '003/057': 'spam',\n",
       " '003/058': 'ham',\n",
       " '003/059': 'ham',\n",
       " '003/060': 'spam',\n",
       " '003/061': 'spam',\n",
       " '003/062': 'spam',\n",
       " '003/063': 'spam',\n",
       " '003/064': 'spam',\n",
       " '003/065': 'ham',\n",
       " '003/066': 'ham',\n",
       " '003/067': 'spam',\n",
       " '003/068': 'spam',\n",
       " '003/069': 'ham',\n",
       " '003/070': 'ham',\n",
       " '003/071': 'spam',\n",
       " '003/072': 'spam',\n",
       " '003/073': 'ham',\n",
       " '003/074': 'spam',\n",
       " '003/075': 'ham',\n",
       " '003/076': 'spam',\n",
       " '003/077': 'ham',\n",
       " '003/078': 'spam',\n",
       " '003/079': 'spam',\n",
       " '003/080': 'spam',\n",
       " '003/081': 'spam',\n",
       " '003/082': 'ham',\n",
       " '003/083': 'spam',\n",
       " '003/084': 'ham',\n",
       " '003/085': 'ham',\n",
       " '003/086': 'spam',\n",
       " '003/087': 'spam',\n",
       " '003/088': 'spam',\n",
       " '003/089': 'spam',\n",
       " '003/090': 'spam',\n",
       " '003/091': 'ham',\n",
       " '003/092': 'ham',\n",
       " '003/093': 'spam',\n",
       " '003/094': 'spam',\n",
       " '003/095': 'spam',\n",
       " '003/096': 'ham',\n",
       " '003/097': 'ham',\n",
       " '003/098': 'spam',\n",
       " '003/099': 'ham',\n",
       " ...}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting Labels from the labels file\n",
    "labels_file = \"trec06p-cs280/labels\"\n",
    "\n",
    "labels_dict = {}\n",
    "\n",
    "with open(labels_file, 'r') as file:\n",
    "    for line in file:\n",
    "        label, file_path = line.strip().split()\n",
    "        cleaned_path = file_path.replace('../data/', '').replace('\\\\', '/')\n",
    "        labels_dict[cleaned_path] = label\n",
    "\n",
    "\n",
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97ae28c7-9033-4da4-9cec-2746c5edbe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "\n",
      "Label: ham, Email: Received: from rodan.UU.NET by aramis.rutgers.edu (5.59/SMI4...\n",
      "\n",
      "Label: spam, Email: Received: from unknown (HELO groucho.cs.psu.edu) ([222.135.2...\n",
      "\n",
      "Label: spam, Email: Received:\n",
      "\tfrom 24-151-178-89.dhcp.kgpt.tn.charter.com (HELO...\n",
      "\n",
      "Label: ham, Email: Received: from psuvax1.cs.psu.edu ([130.203.2.4]) by groucho...\n",
      "\n",
      "Label: spam, Email: Received: from 201-1-198-159.dsl.telesp.net.br (HELO 32A3F2F...\n",
      "\n",
      "\n",
      "Test Set:\n",
      "\n",
      "Label: ham, Email: Received: from cereberos.shinigami.org (IDENT:root@detroit1-...\n",
      "\n",
      "Label: spam, Email: Received: from psy1.psych.arizona.edua (unknown [222.160.107...\n",
      "\n",
      "Label: spam, Email: Received: from wonder.hananet.net (unknown [219.255.79.54])\n",
      "...\n",
      "\n",
      "Label: spam, Email: Received: from media.mit.edu (unknown [85.158.73.138]) by al...\n",
      "\n",
      "Label: spam, Email: Received: from 43458748 (210.211.253.213.bb-dynamic.vsnl.net...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#READ AND COMBINE LABELS + EMAILS\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "base_dir = \"trec06p-cs280/data\"\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file:\n",
    "            # Construct the relative path (e.g., 000/000)\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), base_dir).replace(\"\\\\\", \"/\")\n",
    "\n",
    "            dir_part = relative_path.split(\"/\")[0]\n",
    "            \n",
    "            if dir_part.isdigit():  # Ensure the directory is a number\n",
    "                dir_number = int(dir_part)\n",
    "                \n",
    "                # Read the email content\n",
    "                with open(os.path.join(root, file), 'r', encoding='latin-1', errors='ignore') as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                # Get the label for this file from labels_dict\n",
    "                label = labels_dict.get(relative_path)\n",
    "                \n",
    "                if label:\n",
    "                    # Append the content, label, and directory number\n",
    "                    data.append((content, label, dir_number))\n",
    "                \n",
    "data.sort(key=lambda x: x[2])\n",
    "\n",
    "emails = [email for email, label, dir_number in data]\n",
    "labels = [label for email, label, dir_number in data]\n",
    "directory_numbers = [dir_number for email, label, dir_number in data]\n",
    "\n",
    "#Partition train set and test sets\n",
    "train_emails, test_emails, train_labels, test_labels, train_dirs, test_dirs = train_test_split(\n",
    "    emails, labels, directory_numbers, test_size=0.44, shuffle=False)  # 44% for test as directories 71–127\n",
    "\n",
    "print(\"Training Set:\\n\")\n",
    "for email, label in zip(train_emails[:5], train_labels[:5]):\n",
    "    train_data = list(zip(train_emails, train_labels)) #Train data combined emails and labels of the training set\n",
    "    print(f\"Label: {label}, Email: {email[:60]}...\\n\")\n",
    "\n",
    "\n",
    "print(\"\\nTest Set:\\n\")\n",
    "for email, label in zip(test_emails[:5], test_labels[:5]):\n",
    "    print(f\"Label: {label}, Email: {email[:60]}...\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#Displaying first 5 emails and their labels\n",
    "#Tuple organization: EMAIL , LABEL\n",
    "# for email, label in data[:5]:\n",
    "#     print(f\"Label: {label}, Email: {email[:60]}...\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9359bec-81a3-4216-b56c-d5fec1f2ba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: ham, Email Body: mailing list queried weeks ago running  set archive server  ...\n",
      "\n",
      "Label: spam, Email Body: LUXURY WATCHES BUY ROLEX       Rolex    Cartier    Bvlgari  ...\n",
      "\n",
      "Label: spam, Email Body: Academic Qualifications prestigious NON ACC REDITED uni vers...\n",
      "\n",
      "Label: ham, Email Body: Greetings all  verify subscription plan  fans list  charter ...\n",
      "\n",
      "Label: spam, Email Body: chauncey conferred luscious continued tonsillitis...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DATA CLEANING\n",
    "import email\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "def extract_email_body(email_content):\n",
    "    # Parse the email content into a message object\n",
    "    message = email.message_from_string(email_content, policy=policy.default)\n",
    "\n",
    "    email_body = \"\"\n",
    "\n",
    "    # If the email is multipart (has multiple parts like plain text or HTML)\n",
    "    if message.is_multipart():\n",
    "        for part in message.iter_parts():\n",
    "            # Look for a text/plain part and ignore any text/html parts\n",
    "            if part.get_content_type() == \"text/plain\":\n",
    "                email_body = part.get_payload(decode=True).decode('latin-1', errors='replace')\n",
    "                break\n",
    "    else:\n",
    "        # If it's not multipart, we just decode the payload (assuming it's text)\n",
    "        email_body = message.get_payload(decode=True).decode('latin-1', errors='replace')\n",
    "\n",
    "    # This removes HTML tags using a regex\n",
    "    import re\n",
    "    email_body = re.sub(r'<.*?>', '', email_body)\n",
    "\n",
    "    return email_body\n",
    "\n",
    "\n",
    "\n",
    "def load_stop_words(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        stop_words = {word.strip() for word in f.readlines()}\n",
    "    return stop_words\n",
    "\n",
    "def clean_data(text, stop_words):\n",
    "    # Remove punctuation and replace with space\n",
    "    words = text.split()  # Split text into words\n",
    "    cleaned_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Remove punctuation from each word\n",
    "        cleaned_word = ''.join([char if char not in punctuation and char.isalpha() else ' ' for char in word])\n",
    "        \n",
    "        # If the cleaned word is not a stop word or a single letter except i and a, append it. Otherwise, replace with space\n",
    "        if len(cleaned_word) > 1 and cleaned_word.lower() not in stop_words:\n",
    "            cleaned_words.append(cleaned_word)\n",
    "        # else:\n",
    "        #     cleaned_words.append('')  \n",
    "    \n",
    "    # Join the cleaned words back into a single string\n",
    "    cleaned_text = ' '.join(cleaned_words)\n",
    "    \n",
    "    return cleaned_text.strip()\n",
    "\n",
    "stop_words = load_stop_words('stop_words.txt')\n",
    "processed_data = []\n",
    "punctuation = '!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "\n",
    "for raw_email, label, _ in data[:5]:  # we use \"_\" to ignore dir_number because dir number is for data split only\n",
    "    email_body = extract_email_body(raw_email)\n",
    "    cleaned_email = clean_data(email_body,stop_words)\n",
    "    processed_data.append((cleaned_email,label))\n",
    "\n",
    "for email_body, label in processed_data[:5]:\n",
    "    print(f\"Label: {label}, Email Body: {email_body[:60]}...\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa80d7e2-b1ba-4e6d-ae67-b06a2e9ea7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: http, Total: 17397, Spam: 13021, Ham: 4376\n",
      "Word: com, Total: 17012, Spam: 11808, Ham: 5204\n",
      "Word: will, Total: 10691, Spam: 4733, Ham: 5958\n",
      "Word: edu, Total: 8928, Spam: 306, Ham: 8622\n",
      "Word: www, Total: 7867, Spam: 4002, Ham: 3865\n",
      "Word: nbsp, Total: 6889, Spam: 5641, Ham: 1248\n",
      "Word: board, Total: 4178, Spam: 236, Ham: 3942\n",
      "Word: Adobe, Total: 4050, Spam: 4034, Ham: 16\n",
      "Word: From, Total: 3995, Spam: 47, Ham: 3948\n",
      "Word: CRUST, Total: 3989, Spam: 0, Ham: 3989\n"
     ]
    }
   ],
   "source": [
    "#To list 10000 unique words\n",
    "\n",
    "#Dictionaries to count word occurrences for spam and ham\n",
    "word_count_spam = {}\n",
    "word_count_ham = {}\n",
    "\n",
    "def tokenize_email(email_content):\n",
    "    words = email_content.split()\n",
    "\n",
    "    return [word for word in words if len(word) > 2]\n",
    "\n",
    "for raw_email, label in train_data: \n",
    "    email_body = extract_email_body(raw_email)\n",
    "    cleaned_email = clean_data(email_body, stop_words)\n",
    "\n",
    "    words = tokenize_email(cleaned_email)\n",
    "\n",
    "    if label == 'spam':\n",
    "        for word in words:\n",
    "            if word in word_count_spam:\n",
    "                word_count_spam[word] += 1\n",
    "            else:\n",
    "                word_count_spam[word] = 1\n",
    "\n",
    "    elif label == 'ham':\n",
    "        for word in words:\n",
    "            if word in word_count_ham:\n",
    "                word_count_ham[word] += 1\n",
    "            else:\n",
    "                word_count_ham[word] = 1\n",
    "\n",
    "unique_words = set(word_count_spam.keys()).union(set(word_count_ham.keys()))\n",
    "\n",
    "word_occurrences = []\n",
    "for word in unique_words:\n",
    "    total_count = word_count_spam.get(word, 0) + word_count_ham.get(word, 0)\n",
    "    word_occurrences.append((word, total_count, word_count_spam.get(word, 0), word_count_ham.get(word, 0)))\n",
    "\n",
    "word_occurrences.sort(key=lambda x: x[1], reverse=True)\n",
    "top_10000_words_withcount = word_occurrences[:10000]\n",
    "\n",
    "for word, total, spam_count, ham_count in top_10000_words_withcount[:10]:\n",
    "    print(f\"Word: {word}, Total: {total}, Spam: {spam_count}, Ham: {ham_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa52f571-ff2c-48aa-926b-e8c430241df3",
   "metadata": {},
   "source": [
    "# Forming Feature Matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149c8da5-8df6-4130-937e-4ee1c8f650ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Feature Matrix Shape: (21180, 10000)\n",
      "Testing Feature Matrix Shape: (16642, 10000)\n"
     ]
    }
   ],
   "source": [
    "#get the words only\n",
    "top_10000_words = [word for word, _, _, _ in word_occurrences[:10000]]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def generate_feature_matrix(emails, word_list):\n",
    "    \"\"\"\n",
    "    Generate a feature matrix for emails based on the presence of words in word_list.\n",
    "    \"\"\"\n",
    "    matrix = np.zeros((len(emails), len(word_list)), dtype=int)\n",
    "    \n",
    "    for i, raw_email in enumerate(emails):\n",
    "        email_body = extract_email_body(raw_email)\n",
    "        cleaned_email = clean_data(email_body, stop_words)\n",
    "        # Tokenize the cleaned email\n",
    "        words = set(tokenize_email(cleaned_email))\n",
    "        \n",
    "        # Update the matrix with 1 if the word exists in the email\n",
    "        for j, word in enumerate(word_list):\n",
    "            if word in words:\n",
    "                matrix[i, j] = 1\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "# Generate the training and testing feature matrices\n",
    "train_features = generate_feature_matrix(train_emails, top_10000_words)\n",
    "test_features = generate_feature_matrix(test_emails, top_10000_words)\n",
    "\n",
    "print(\"Training Feature Matrix Shape:\", train_features.shape)\n",
    "print(\"Testing Feature Matrix Shape:\", test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af6730-0c90-4b47-b18a-20bf2825b422",
   "metadata": {},
   "source": [
    "# Computing the priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "171dec7b-6349-4d9f-b6d7-6447809209f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(c = spam) = 0.6461756373937677\n",
      "P(c = ham) = 0.3538243626062323\n"
     ]
    }
   ],
   "source": [
    "# Count the number of spam and ham emails\n",
    "N_spam = train_labels.count('spam')\n",
    "N_ham = train_labels.count('ham')\n",
    "\n",
    "# Total number of emails in the training set\n",
    "N_doc = len(train_labels)\n",
    "\n",
    "# Compute the priors\n",
    "P_spam = N_spam / N_doc\n",
    "P_ham = N_ham / N_doc\n",
    "\n",
    "print(f\"P(c = spam) = {P_spam}\")\n",
    "print(f\"P(c = ham) = {P_ham}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1359547-144c-40af-a8be-4c32c223f35d",
   "metadata": {},
   "source": [
    "# Computing for the Likelihood of each word (With dictionary filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3014534f-7083-438a-9428-84f5fcb70ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Filtering words with occurrence > 1000 ---\n",
      "Vocabulary size after filtering: 147\n",
      "Word: port, P(w|spam): 6.547502127938192e-06, P(w|ham): 0.008132352853754377\n",
      "Word: List, P(w|spam): 6.547502127938192e-06, P(w|ham): 0.008613873746410886\n",
      "Word: Professional, P(w|spam): 0.017246120604989198, P(w|ham): 5.944702378475422e-06\n",
      "Word: robot, P(w|spam): 6.547502127938192e-06, P(w|ham): 0.007092029937521178\n",
      "Word: Message, P(w|spam): 6.547502127938192e-06, P(w|ham): 0.008590094936896985\n",
      "Word: Received, P(w|spam): 6.547502127938192e-06, P(w|ham): 0.013851156541847733\n",
      "Word: class, P(w|spam): 0.009022457932298828, P(w|ham): 5.944702378475422e-06\n",
      "Word: handyboard, P(w|spam): 6.547502127938192e-06, P(w|ham): 0.01043889737660284\n",
      "Word: style, P(w|spam): 0.017580043213514043, P(w|ham): 5.944702378475422e-06\n",
      "Word: size, P(w|spam): 0.02068355922215675, P(w|ham): 5.944702378475422e-06\n",
      "\n",
      "--- Filtering words with occurrence > 100 ---\n",
      "Vocabulary size after filtering: 2835\n",
      "Word: track, P(w|spam): 1.922744140437232e-06, P(w|ham): 0.00026006536868880076\n",
      "Word: provided, P(w|spam): 1.922744140437232e-06, P(w|ham): 0.00039429265575398825\n",
      "Word: robot, P(w|spam): 1.922744140437232e-06, P(w|ham): 0.0020016644183596085\n",
      "Word: Grounded, P(w|spam): 0.00042300371089619106, P(w|ham): 1.6778410883148434e-06\n",
      "Word: center, P(w|spam): 0.00032878924801476667, P(w|ham): 0.00020637445386272575\n",
      "Word: TIC, P(w|spam): 1.922744140437232e-06, P(w|ham): 0.00019127388406789216\n",
      "Word: turned, P(w|spam): 0.0006095098925186026, P(w|ham): 0.00033053469439802417\n",
      "Word: mouse, P(w|spam): 1.922744140437232e-06, P(w|ham): 0.00021476365930429996\n",
      "Word: USD, P(w|spam): 1.922744140437232e-06, P(w|ham): 0.00017785115536137343\n",
      "Word: verified, P(w|spam): 0.00033263473629564116, P(w|ham): 1.6778410883148434e-06\n",
      "\n",
      "--- Filtering words with occurrence > 50 ---\n",
      "Vocabulary size after filtering: 5130\n",
      "Word: art, P(w|spam): 1.6349005489996044e-06, P(w|ham): 9.924615456596112e-05\n",
      "Word: acm, P(w|spam): 1.6349005489996044e-06, P(w|ham): 9.357494573362048e-05\n",
      "Word: redi, P(w|spam): 0.00013569674556696717, P(w|ham): 1.417802208085159e-06\n",
      "Word: BGAAYAAUABQDw, P(w|spam): 1.6349005489996044e-06, P(w|ham): 8.648593469319469e-05\n",
      "Word: turned, P(w|spam): 0.0005182634740328746, P(w|ham): 0.0002793070349927763\n",
      "Word: EBOF, P(w|spam): 0.0001128081378809727, P(w|ham): 1.417802208085159e-06\n",
      "Word: nous, P(w|spam): 0.00013242694446896795, P(w|ham): 1.417802208085159e-06\n",
      "Word: USD, P(w|spam): 0.000156950452703962, P(w|ham): 0.00015028703405702684\n",
      "Word: Coordinator, P(w|spam): 8.664972909697903e-05, P(w|ham): 1.417802208085159e-06\n",
      "Word: Russ, P(w|spam): 1.6349005489996044e-06, P(w|ham): 0.00010066395677404628\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import email\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "# Function to filter word counts based on occurrence threshold\n",
    "def filter_word_counts(word_counts, k):\n",
    "    return {word: count for word, count in word_counts.items() if count > k}\n",
    "\n",
    "# Experiment with different thresholds\n",
    "thresholds = [1000, 100, 50]  # Experiment thresholds\n",
    "results = {}\n",
    "\n",
    "for k in thresholds:\n",
    "    print(f\"\\n--- Filtering words with occurrence > {k} ---\")\n",
    "    \n",
    "    # Filter word counts based on threshold\n",
    "    filtered_word_count_spam = filter_word_counts(word_count_spam, k)\n",
    "    filtered_word_count_ham = filter_word_counts(word_count_ham, k)\n",
    "\n",
    "    # Recompute vocabulary\n",
    "    vocabulary = set(filtered_word_count_spam.keys()).union(set(filtered_word_count_ham.keys()))\n",
    "    vocab_size = len(vocabulary)\n",
    "\n",
    "    # Recompute total word counts for spam and ham\n",
    "    total_spam_words = sum(filtered_word_count_spam.values())\n",
    "    total_ham_words = sum(filtered_word_count_ham.values())\n",
    "\n",
    "    # Laplace smoothing parameter\n",
    "    lambda_ = 1\n",
    "\n",
    "    # Compute likelihoods for each word\n",
    "    likelihood_spam = {}\n",
    "    likelihood_ham = {}\n",
    "\n",
    "    for word in vocabulary:\n",
    "        # P(w|spam)\n",
    "        likelihood_spam[word] = (filtered_word_count_spam.get(word, 0) + lambda_) / (total_spam_words + vocab_size * lambda_)\n",
    "        # P(w|ham)\n",
    "        likelihood_ham[word] = (filtered_word_count_ham.get(word, 0) + lambda_) / (total_ham_words + vocab_size * lambda_)\n",
    "\n",
    "    # Save results\n",
    "    results[k] = {\n",
    "        'vocab_size': vocab_size,\n",
    "        'likelihood_spam': likelihood_spam,\n",
    "        'likelihood_ham': likelihood_ham,\n",
    "    }\n",
    "\n",
    "    # Display some examples\n",
    "    print(f\"Vocabulary size after filtering: {vocab_size}\")\n",
    "    for word in list(vocabulary)[:10]:  # Show first 10 words\n",
    "        print(f\"Word: {word}, P(w|spam): {likelihood_spam[word]}, P(w|ham): {likelihood_ham[word]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7c718a-45ca-47b5-b38a-2f0e0163c97f",
   "metadata": {},
   "source": [
    "# Classfying the emails and Implementing on \"Test_emails\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94747ef5-1912-4b1f-a0e4-839ba256d847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying Test Emails with Threshold k = 50:\n",
      "\n",
      "Email 1:\n",
      "Content: Received: from cereberos.shinigami.org (IDENT:root@detroit1-...\n",
      "Predicted: ham, Actual: ham\n",
      "\n",
      "Email 2:\n",
      "Content: Received: from psy1.psych.arizona.edua (unknown [222.160.107...\n",
      "Predicted: spam, Actual: spam\n",
      "\n",
      "Email 3:\n",
      "Content: Received: from wonder.hananet.net (unknown [219.255.79.54])\n",
      "...\n",
      "Predicted: spam, Actual: spam\n",
      "\n",
      "Email 4:\n",
      "Content: Received: from media.mit.edu (unknown [85.158.73.138]) by al...\n",
      "Predicted: spam, Actual: spam\n",
      "\n",
      "Email 5:\n",
      "Content: Received: from 43458748 (210.211.253.213.bb-dynamic.vsnl.net...\n",
      "Predicted: spam, Actual: spam\n",
      "\n",
      "Accuracy[50] = 92.46%\n",
      "\n",
      "Classifying Test Emails with Threshold k = 100:\n",
      "\n",
      "Email 1:\n",
      "Content: Received: from cereberos.shinigami.org (IDENT:root@detroit1-...\n",
      "Predicted: ham, Actual: ham\n",
      "\n",
      "Email 2:\n",
      "Content: Received: from psy1.psych.arizona.edua (unknown [222.160.107...\n",
      "Predicted: spam, Actual: spam\n",
      "\n",
      "Email 3:\n",
      "Content: Received: from wonder.hananet.net (unknown [219.255.79.54])\n",
      "...\n",
      "Predicted: spam, Actual: spam\n",
      "\n",
      "Email 4:\n",
      "Content: Received: from media.mit.edu (unknown [85.158.73.138]) by al...\n",
      "Predicted: spam, Actual: spam\n",
      "\n",
      "Email 5:\n",
      "Content: Received: from 43458748 (210.211.253.213.bb-dynamic.vsnl.net...\n",
      "Predicted: spam, Actual: spam\n",
      "\n",
      "Accuracy[100] = 91.68%\n",
      "\n",
      "Classifying Test Emails with Threshold k = 1000:\n",
      "\n",
      "Email 1:\n",
      "Content: Received: from cereberos.shinigami.org (IDENT:root@detroit1-...\n",
      "Predicted: ham, Actual: ham\n",
      "\n",
      "Email 2:\n",
      "Content: Received: from psy1.psych.arizona.edua (unknown [222.160.107...\n",
      "Predicted: spam, Actual: spam\n",
      "\n",
      "Email 3:\n",
      "Content: Received: from wonder.hananet.net (unknown [219.255.79.54])\n",
      "...\n",
      "Predicted: spam, Actual: spam\n",
      "\n",
      "Email 4:\n",
      "Content: Received: from media.mit.edu (unknown [85.158.73.138]) by al...\n",
      "Predicted: spam, Actual: spam\n",
      "\n",
      "Email 5:\n",
      "Content: Received: from 43458748 (210.211.253.213.bb-dynamic.vsnl.net...\n",
      "Predicted: ham, Actual: spam\n",
      "\n",
      "Accuracy[1000] = 86.05%\n",
      "\n",
      "Final Results:\n",
      "Accuracy[50] = 92.46%\n",
      "Accuracy[100] = 91.68%\n",
      "Accuracy[1000] = 86.05%\n"
     ]
    }
   ],
   "source": [
    "# Thresholds to evaluate\n",
    "thresholds = [50, 100, 1000]\n",
    "accuracies = {}\n",
    "\n",
    "# Recompute priors\n",
    "prior_spam = N_spam / N_doc\n",
    "prior_ham = N_ham / N_doc\n",
    "log_prior_spam = np.log(prior_spam)\n",
    "log_prior_ham = np.log(prior_ham)\n",
    "\n",
    "# Function to classify an email\n",
    "def classify_email(email_content, likelihood_spam, likelihood_ham, log_prior_spam, log_prior_ham):\n",
    "    # Preprocess email\n",
    "    email_body = extract_email_body(email_content)\n",
    "    cleaned_email = clean_data(email_body, stop_words)\n",
    "    words = tokenize_email(cleaned_email)\n",
    "    \n",
    "    # Compute log probabilities\n",
    "    log_prob_spam = log_prior_spam\n",
    "    log_prob_ham = log_prior_ham\n",
    "    \n",
    "    for word in words:\n",
    "        # Use vocab_size and word counts derived from the filtered likelihoods\n",
    "        log_prob_spam += np.log(likelihood_spam.get(word, 1 / (total_spam_words + vocab_size)))\n",
    "        log_prob_ham += np.log(likelihood_ham.get(word, 1 / (total_ham_words + vocab_size)))\n",
    "    \n",
    "    # Classification\n",
    "    return \"spam\" if log_prob_spam > log_prob_ham else \"ham\"\n",
    "\n",
    "\n",
    "for k in thresholds:\n",
    "    # Filtered likelihoods and vocabulary size for the current threshold\n",
    "    filtered_likelihoods = results[k]\n",
    "    likelihood_spam = filtered_likelihoods['likelihood_spam']\n",
    "    likelihood_ham = filtered_likelihoods['likelihood_ham']\n",
    "    vocab_size = filtered_likelihoods['vocab_size']\n",
    "    \n",
    "    \n",
    "    # Initialize counters\n",
    "    correct_predictions = 0\n",
    "    total_emails = len(test_emails)\n",
    "    \n",
    "    print(f\"Classifying Test Emails with Threshold k = {k}:\\n\")\n",
    "    \n",
    "    for i, raw_email in enumerate(test_emails):\n",
    "        # Classify each email\n",
    "        predicted_label = classify_email(\n",
    "            raw_email, likelihood_spam, likelihood_ham, \n",
    "            log_prior_spam, log_prior_ham \n",
    "            )\n",
    "        actual_label = test_labels[i]\n",
    "        \n",
    "        # Check if prediction matches the actual label\n",
    "        if predicted_label == actual_label:\n",
    "            correct_predictions += 1\n",
    "        \n",
    "        # Print sample results for debugging\n",
    "        if i < 5:  # Show results for first 5 emails\n",
    "            print(f\"Email {i+1}:\")\n",
    "            print(f\"Content: {raw_email[:60]}...\")\n",
    "            print(f\"Predicted: {predicted_label}, Actual: {actual_label}\\n\")\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_emails * 100\n",
    "    accuracies[k] = accuracy  # Store accuracy for this threshold\n",
    "    print(f\"Accuracy[{k}] = {accuracy:.2f}%\\n\")\n",
    "\n",
    "# Final Results\n",
    "print(\"Final Results:\")\n",
    "for k, acc in accuracies.items():\n",
    "    print(f\"Accuracy[{k}] = {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12602eae-6cc4-4f68-939c-8a47f5909843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating for Threshold k=50\n",
      "Evaluation Metrics for k=50:\n",
      "Accuracy: 92.34%\n",
      "Recall: 92.21%\n",
      "Precision: 96.28%\n",
      "\n",
      "Confusion Matrix:\n",
      "True Positive (TP): 10351\n",
      "True Negative (TN): 5016\n",
      "False Positive (FP): 400\n",
      "False Negative (FN): 875\n",
      "\n",
      "Evaluating for Threshold k=100\n",
      "Evaluation Metrics for k=100:\n",
      "Accuracy: 91.37%\n",
      "Recall: 90.97%\n",
      "Precision: 96.02%\n",
      "\n",
      "Confusion Matrix:\n",
      "True Positive (TP): 10212\n",
      "True Negative (TN): 4993\n",
      "False Positive (FP): 423\n",
      "False Negative (FN): 1014\n",
      "\n",
      "Evaluating for Threshold k=1000\n",
      "Evaluation Metrics for k=1000:\n",
      "Accuracy: 85.99%\n",
      "Recall: 86.85%\n",
      "Precision: 91.94%\n",
      "\n",
      "Confusion Matrix:\n",
      "True Positive (TP): 9750\n",
      "True Negative (TN): 4561\n",
      "False Positive (FP): 855\n",
      "False Negative (FN): 1476\n",
      "\n",
      "Summary of Results:\n",
      "Threshold k=50:\n",
      "  Accuracy: 92.34%\n",
      "  Recall: 92.21%\n",
      "  Precision: 96.28%\n",
      "Threshold k=100:\n",
      "  Accuracy: 91.37%\n",
      "  Recall: 90.97%\n",
      "  Precision: 96.02%\n",
      "Threshold k=1000:\n",
      "  Accuracy: 85.99%\n",
      "  Recall: 86.85%\n",
      "  Precision: 91.94%\n"
     ]
    }
   ],
   "source": [
    "# Initialize thresholds\n",
    "thresholds = [50, 100, 1000]\n",
    "\n",
    "# Results storage\n",
    "results = {}\n",
    "\n",
    "# Loop through each threshold\n",
    "for k in thresholds:\n",
    "    print(f\"\\nEvaluating for Threshold k={k}\")\n",
    "\n",
    "    # Filter the dictionary to include words occurring more than k times\n",
    "    filtered_word_count_spam = {word: count for word, count in word_count_spam.items() if count > k}\n",
    "    filtered_word_count_ham = {word: count for word, count in word_count_ham.items() if count > k}\n",
    "\n",
    "    # Vocabulary and word counts\n",
    "    vocabulary = set(filtered_word_count_spam.keys()).union(set(filtered_word_count_ham.keys()))\n",
    "    vocab_size = len(vocabulary)\n",
    "\n",
    "    total_spam_words = sum(filtered_word_count_spam.values())\n",
    "    total_ham_words = sum(filtered_word_count_ham.values())\n",
    "\n",
    "    # Compute likelihoods for filtered words\n",
    "    likelihood_spam = {\n",
    "        word: (filtered_word_count_spam.get(word, 0) + lambda_) / (total_spam_words + vocab_size * lambda_)\n",
    "        for word in vocabulary\n",
    "    }\n",
    "    likelihood_ham = {\n",
    "        word: (filtered_word_count_ham.get(word, 0) + lambda_) / (total_ham_words + vocab_size * lambda_)\n",
    "        for word in vocabulary\n",
    "    }\n",
    "\n",
    "    # Example priors (from earlier computation)\n",
    "    prior_spam = N_spam / N_doc\n",
    "    prior_ham = N_ham / N_doc\n",
    "\n",
    "    # Log of priors\n",
    "    log_prior_spam = np.log(prior_spam)\n",
    "    log_prior_ham = np.log(prior_ham)\n",
    "\n",
    "    # Initialize counters for evaluation metrics\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    # Evaluate each email\n",
    "    for i, email_content in enumerate(test_emails):\n",
    "        # Get the actual and predicted labels\n",
    "        actual_label = test_labels[i]\n",
    "        predicted_label = classify_email(email_content, likelihood_spam, likelihood_ham, log_prior_spam, log_prior_ham)\n",
    "\n",
    "        # Update counts based on comparison\n",
    "        if actual_label == \"spam\" and predicted_label == \"spam\":\n",
    "            true_positive += 1\n",
    "        elif actual_label == \"ham\" and predicted_label == \"ham\":\n",
    "            true_negative += 1\n",
    "        elif actual_label == \"ham\" and predicted_label == \"spam\":\n",
    "            false_positive += 1\n",
    "        elif actual_label == \"spam\" and predicted_label == \"ham\":\n",
    "            false_negative += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) != 0 else 0\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) != 0 else 0\n",
    "\n",
    "    # Store results\n",
    "    results[k] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"confusion_matrix\": {\n",
    "            \"TP\": true_positive,\n",
    "            \"TN\": true_negative,\n",
    "            \"FP\": false_positive,\n",
    "            \"FN\": false_negative\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Print the metrics for the current threshold\n",
    "    print(f\"Evaluation Metrics for k={k}:\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(f\"True Positive (TP): {true_positive}\")\n",
    "    print(f\"True Negative (TN): {true_negative}\")\n",
    "    print(f\"False Positive (FP): {false_positive}\")\n",
    "    print(f\"False Negative (FN): {false_negative}\")\n",
    "\n",
    "# Summary of results\n",
    "print(\"\\nSummary of Results:\")\n",
    "for k, metrics in results.items():\n",
    "    print(f\"Threshold k={k}:\")\n",
    "    print(f\"  Accuracy: {metrics['accuracy'] * 100:.2f}%\")\n",
    "    print(f\"  Recall: {metrics['recall'] * 100:.2f}%\")\n",
    "    print(f\"  Precision: {metrics['precision'] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387ae0e-3f7a-4ee2-be75-f2c1d0e0f28a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
